:_module-type: REFERENCE

[id='supported-model-serving-runtimes_{context}']
= Supported model-serving runtimes

[role='_abstract']

{productname-short} includes several preinstalled model-serving runtimes. You can use preinstalled model-serving runtimes to start serving models without modifying or defining the runtime yourself. You can also add a custom runtime to support a model. 

See link:https://access.redhat.com/articles/rhoai-supported-configs[Supported configurations] for a list of the supported model-serving runtimes and deployment requirements.

ifdef::upstream[]
For help adding a custom runtime, see link:{odhdocshome}/configuring-your-model-serving-platform/#adding-a-custom-model-serving-runtime-for-the-single-model-serving-platform_odh-admin[Adding a custom model-serving runtime for the single-model serving platform].
endif::[]

ifndef::upstream[]
For help adding a custom runtime, see link:{rhoaidocshome}{default-format-url}/configuring_your_model-serving_platform/configuring_model_servers_on_the_single_model_serving_platform#adding-a-custom-model-serving-runtime-for-the-single-model-serving-platform_rhoai-admin[Adding a custom model-serving runtime for the single-model serving platform].
endif::[]

[role="_additional-resources"]
.Additional resources
ifdef::upstream[]
* link:{odhdocshome}/deploying-models/#inference-endpoints_odh-user[Inference endpoints]
endif::[]

ifndef::upstream[]
* link:{rhoaidocshome}{default-format-url}/deploying_models/making_inference_requests_to_deployed_models#inference-endpoints_rhoai-user[Inference endpoints]
endif::[]

