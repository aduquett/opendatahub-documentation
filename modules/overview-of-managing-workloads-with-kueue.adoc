:_module-type: CONCEPT

[id="overview-of-managing-workloads-with-kueue_{context}"]
= Overview of managing workloads with Kueue

[role="_abstract"]
You can use Kueue in {productname-short} to manage AI and machine learning workloads at scale. Kueue controls how cluster resources are allocated and shared through hierarchical quota management, dynamic resource allocation, and prioritized job scheduling. These capabilities help prevent cluster contention, ensure fair access across teams, and optimize the use of heterogeneous compute resources, such as hardware accelerators.

Kueue lets you schedule diverse workloads, including distributed training jobs (`RayJob`, `RayCluster`, `PyTorchJob`), workbenches (`Notebook`), and model serving (`InferenceService`). Kueue validation and queue enforcement apply only to workloads in namespaces with the `kueue.openshift.io/managed=true` label.

Using Kueue in {productname-short} provides these benefits:

* Prevents resource conflicts and prioritizes workload processing
* Manages quotas across teams and projects
* Ensures consistent scheduling for all workload types
* Maximizes GPU and other specialized hardware utilization

ifndef::upstream[]
[IMPORTANT]
====
ifdef::self-managed[]
Starting with {productname-short} 2.24, the embedded Kueue component for managing distributed workloads is deprecated. 
endif::[]
ifdef::cloud-service[]
The embedded Kueue component for managing distributed workloads is deprecated. 
endif::[]
Kueue is now provided through {rhbok-productname}, which is installed and managed by the {rhbok-productname} Operator. You cannot install both the embedded Kueue and the {rhbok-productname} Operator on the same cluster because this creates conflicting controllers that manage the same resources.

{productname-short} does not automatically migrate existing workloads. To ensure your workloads continue using queue management after upgrading, cluster administrators must manually migrate from the embedded Kueue to the {rhbok-productname} Operator. For more information, see link:{rhoaidocshome}{default-format-url}/managing_openshift_ai/managing-workloads-with-kueue#migrating-to-the-rhbok-operator_kueue[Migrating to the {rhbok-productname} Operator].
====
endif::[]


== Kueue management states

You configure how {productname-short} interacts with Kueue by setting the `managementState` in the `DataScienceCluster` object.

`Unmanaged`::
This state is supported for using Kueue with {productname-short}. In `Unmanaged` state, {productname-short} integrates with an existing Kueue installation managed by the {rhbok-productname} Operator. You must have the {rhbok-productname} Operator installed and running on the cluster.
+
When you enable `Unmanaged` mode, the {productname-short} Operator creates a default `Kueue` custom resource (CR) if one does not already exist. This prompts the {rhbok-productname} Operator to activate Kueue on the cluster.

`Managed`::
This state is deprecated. Previously, {productname-short} deployed and managed an embedded Kueue distribution. `Managed` mode is not compatible with the {rhbok-productname} Operator. If both are installed, {productname-short} stops reconciliation to avoid conflicts. You must migrate any environment using the `Managed` state to the `Unmanaged` state to ensure continued support. 

`Removed`::
This state disables Kueue in {productname-short}. If the state was previously `Managed`, {productname-short} uninstalls the embedded Kueue distribution. If the state was previously `Unmanaged`, {productname-short} stops checking for the external Kueue integration but does not uninstall the {rhbok-productname} Operator. An empty `managementState` value also functions as `Removed`.

== Queue enforcement for projects

To ensure workloads do not bypass the queuing system, a validating webhook automatically enforces queuing rules on any project that is enabled for Kueue management. You enable a project for Kueue management by applying the `kueue.openshift.io/managed=true` label to the project namespace. 

[NOTE]  
====  
This validating webhook enforcement method replaces the Validating Admission Policy that was used with the deprecated embedded Kueue component. The system also supports the legacy `kueue-managed` label for backward compatibility, but `kueue.openshift.io/managed=true` is the recommended label going forward.  
====  

After a project is enabled for Kueue management, the webhook requires that any new or updated workload has the `kueue.x-k8s.io/queue-name` label. If this label is missing, the webhook prevents the workload from being created or updated.  

{productname-short} creates a default, cluster-scoped `ClusterQueue` (if one does not already exist) and a namespace-scoped `LocalQueue` for that namespace (if one does not already exist). These default resources are created with the `opendatahub.io/managed=false` annotation, so they are not managed after creation. Cluster administrators can change or delete them.

The webhook enforces this rule on the `create` and `update` operations for the following resource types:

* `InferenceService`
* `Notebook`
* `PyTorchJob`
* `RayCluster`
* `RayJob`

[NOTE]
====
You can apply hardware profiles to other workload types, but the validation webhook enforces the `kueue.x-k8s.io/queue-name` label requirement only for these specific resource types.
====

== Restrictions for managing workloads with Kueue

When you use Kueue to manage workloads in {productname-short}, the following restrictions apply:

* Namespaces must be labeled with `kueue.openshift.io/managed=true` to enable Kueue validation and queue enforcement.
* All workloads that you create from the {productname-short} dashboard, such as workbenches and model servers, must use a hardware profile that specifies a local queue.
* When you specify a local queue in a hardware profile, {productname-short} automatically applies the corresponding `kueue.x-k8s.io/queue-name` label to workloads that use that profile.
* You cannot use hardware profiles that contain node selectors or tolerations for node placement. To direct workloads to specific nodes, use a hardware profile that specifies a local queue that is associated with a queue configured with the appropriate resource flavors.
* You cannot use accelerator profiles with Kueue. You must migrate any existing accelerator profiles to hardware profiles.
* Because workbenches are not suspendable workloads, you can only assign them to a local queue that is associated with a non-preemptive cluster queue. The default cluster queue that {productname-short} creates is non-preemptive.

.Additional resources
* link:{rhbok-docs}[{rhbok-productname} documentation]
