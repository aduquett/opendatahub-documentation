:_module-type: PROCEDURE

[id='controlling-caching-in-data-science-pipelines_{context}']
= Controlling caching in data science pipelines

[role='_abstract']
Caching is enabled by default in {productname-short} to improve performance. However, there are instances when disabling caching might be necessary for specific tasks, an entire pipeline, or all pipelines. For example, caching might not be beneficial for tasks that rely on frequently updated data or unique computational needs. In other cases, such as debugging, development, or when deterministic re-execution is required, you might want to disable caching for all pipelines.

[CAUTION]
====
Disabling caching at the pipeline or pipeline server level causes all tasks to re-run, potentially increasing compute time and resource usage.
====

You can control caching for data science pipelines in the following ways:

* *Individual task*: Data scientists can disable caching for specific steps in a pipeline.
* *Pipeline (submit time)*: Data scientists can disable caching when submitting a pipeline run.
* *Pipeline (compile time)*: Data scientists can disable caching when compiling a pipeline.
* *All pipelines (pipeline server)*: You can disable caching for all pipelines in the pipeline server, which overrides all pipeline and task-level caching settings. 

== Disabling caching for individual tasks

To disable caching for a particular task, apply the `set_caching_options` method directly to the task in your pipeline code:

[source]
----
task_name.set_caching_options(False)
----

After applying this setting, {productname-short} runs the task in future pipeline runs, ignoring any cached results.

You can re-enable caching for individual tasks by setting the `set_caching_options` parameter to `True` or by omitting `set_caching_options`.

This setting is ignored if caching is disabled in the pipeline server.

== Disabling caching for a pipeline at submit time

To disable caching for the entire pipeline during pipeline submission, set the `enable_caching` parameter to `False` in your pipeline code. This setting ensures that no steps are cached during pipeline execution. The `enable_caching` parameter is available only when using the `kfp.client` to submit pipelines or start pipeline runs, such as the `run_pipeline` method.

Example:

[source,python]
----
import kfp
client = kfp.Client()
client.run_pipeline(
    experiment_id=experiment.id,
    pipeline_id=pipeline.id,
    job_name="no-cache-run",
    params={},                # optional
    enable_caching=False,
)
----

This setting is ignored if caching is disabled during pipeline compilation or in the pipeline server.

== Disabling caching for a pipeline at compile time

To disable caching for the entire pipeline during compilation, set one of the following options in your local environment or workbench:

* Environment variable:
+
[source,bash]
----
export KFP_DISABLE_EXECUTION_CACHING_BY_DEFAULT=true
----

* CLI flag (when using `kfp dsl compile`):
+
[source,bash]
----
kfp dsl compile --disable-execution-caching-by-default
----

These settings are ignored if caching is disabled in the pipeline server.

== Disabling caching for all pipelines (pipeline server)

To disable caching for all pipelines in the pipeline server and override all pipeline and task-level caching settings, use either of the following methods:

Pipeline server configuration::
+ 
. From the {productname-short} dashboard, click *Data science pipelines* -> *Pipelines*.
. On the *Pipelines* page, from the *Project* drop-down list, select the project that contains the pipeline server that you want to configure.
. From the *Pipeline server actions* list, select *Manage pipeline server configuration*.
. In the *Pipeline caching* section, clear the *Allow caching to be configured per pipeline and task* checkbox.
. Click *Save*.

Data Science Pipelines Application (cluster administrator)::
+
In the {openshift-platform} console or CLI, set the `cacheEnabled` field to `false` in the `DataSciencePipelinesApplication` (DSPA) custom resource for the project. 
+
Example:
+
[source,yaml]
----
apiVersion: datasciencepipelinesapplications.opendatahub.io/v1
kind: DataSciencePipelinesApplication
metadata:
  name: my-dspa
  namespace: my-namespace
spec:
  apiServer:
    cacheEnabled: false
----
+
To allow caching to be configured at the pipeline and task level, set the `cacheEnabled` field to `true` in the DSPA custom resource.


After applying this setting, all pipeline and task-level caching settings are ignored.

[NOTE]
====
Changing this setting updates the `CACHEENABLED` environment variable in the pipeline server deployment. 
====

.Verification

After configuring caching settings, you can verify its behavior by using one of the following methods:

* *Check the UI*: Locate the green icons in the task list to identify cached steps.
* *Test task re-runs*: Disable caching on specific tasks or the pipeline to confirm that steps re-execute as expected.
* *Validate inputs*: Ensure the task inputs, parameters, and runtime settings are unchanged when caching is applied.

[NOTE]
====
You can also disable caching for a single node or for your entire pipeline in JupyterLab using Elyra.
ifdef::upstream[]
For more information, see link:{odhdocshome}/working-with-data-science-pipelines/#disabling-node-caching-in-elyra_ds-pipelines[Disabling node caching in Elyra].
endif::[]
ifndef::upstream[]
For more information, see link:{rhoaidocshome}{default-format-url}/working_with_data_science_pipelines/working-with-pipelines-in-jupyterlab_ds-pipelines#disabling-node-caching-in-elyra_ds-pipelines[Disabling node caching in Elyra].
endif::[]
====

[role="_additional-resources"]
.Additional resources
* Kubeflow caching documentation: link:https://www.kubeflow.org/docs/components/pipelines/user-guides/core-functions/caching/[Kubeflow Pipelines - Use Caching]
* The `kfp.client` module documentation for the `enable_caching` parameter: link:https://kubeflow-pipelines.readthedocs.io/en/stable/source/client.html#kfp.client.Client.run_pipeline.enable_caching[KFP SDK API Reference - kfp.client]
