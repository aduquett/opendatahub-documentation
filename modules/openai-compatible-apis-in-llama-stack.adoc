:_module-type: REFERENCE
[id="openai-compatible-apis-in-Llama-Stack_{context}"]
= OpenAI-compatible APIs in Llama Stack

[role="_abstract"]
{productname-short} includes a Llama Stack component that exposes OpenAI-compatible APIs. These APIs enable you to reuse existing OpenAI SDKs, tools, and workflows directly within your {openshift-platform} environment, without changing your client code. This compatibility layer supports retrieval-augmented generation (RAG), inference, and embedding workloads by using the same endpoints, schemas, and authentication model as OpenAI.

This compatibility layer has the following capabilities:

* *Standardized endpoints*: REST API paths align with OpenAI specifications.  
* *Schema parity:* Request and response fields follow OpenAI data structures.  
* *Authentication:* OpenAI-formatted API keys managed through {productname-short}.  
* *Error handling:* Consistent error codes and response messages.  
* *Usage tracking:* Integrated rate-limit and quota monitoring in the platform.

[NOTE]
====
When connecting OpenAI SDKs or third-party tools to {productname-short}, you must update the client configuration to use your deployment's Llama Stack route as the `base_url`. This ensures that API calls are sent to the OpenAI-compatible endpoints that run inside your {openshift-platform} cluster, rather than to the public OpenAI service.
====

== Supported OpenAI-compatible APIs in {productname-short}

=== Chat Completions API
* *Endpoint:* `/v1/openai/vl/chat/completions`.  
* *Compatibility:* Full OpenAI API parity.
* *Providers:* All inference back ends deployed through {productname-short}.

The Chat Completions API enables conversational, message-based interactions with models served by Llama Stack in {productname-short}.

---

=== Completions API
* *Endpoint:* `/v1/openai/v1/completions`.  
* *Compatibility:* Full OpenAI API parity.  
* *Providers:* All inference backends managed by {productname-short}.

The Completions API supports single-turn text generation and prompt completion.

---

=== Embeddings API
* *Endpoint:* `/v1/openai/v1/embeddings`.  
* *Compatibility:* Full OpenAI API parity. 
* *Providers:* All embedding models enabled in {productname-short}.

The Embeddings API generates numerical embeddings for text or documents that can be used in downstream semantic search or RAG applications.

---

=== Files API
* *Endpoint:* `/v1/openai/v1/files`.  
* *Compatibility:* Full OpenAI API parity. 
* *Providers:* Your local machine's file system.

The Files API manages file uploads for use in embedding and retrieval workflows.

---

=== Vector Store Files API
* *Endpoint:* `/v1/openai/v1/vector_stores/{vector_store_id}/files`.  
* *Compatibility:* Full OpenAI API parity. 
* *Providers:* **Milvus (inline and remote)** configured within {productname-short}.

The Vector Store Files API implements the OpenAI Vector Store Files interface and manages the link between document files and Milvus vector stores used for RAG. 

---

=== Models API
* *Endpoint:* `/v1/openai/v1/models`.  
* *Compatibility:* Full OpenAI API parity.  
* *Providers:* All model-serving back ends configured within {productname-short}.

The Models API lists and retrieves available model resources from the Llama Stack deployment running on {productname-short}. By using the Models API, you can enumerate models, view their capabilities, and verify deployment status through a standardized OpenAI-compatible interface.

---

=== Responses API
* *Endpoint:* `/v1/openai/v1/responses`.  
* *Compatibility:* Experimental OpenAI API parity.  
* *Providers:* All inference and retrieval providers configured in {productname-short}.

The Responses API generates model outputs by combining inference, file search, and tool-calling capabilities through a single OpenAI-compatible endpoint. It is particularly useful for retrieval-augmented generation (RAG) workflows that rely on the `file_search` tool to retrieve context from vector stores.

[NOTE]
====
The Responses API is an experimental feature that is currently in active development and might have limited support or stability. It is provided for evaluation and feedback purposes only and is not recommended for production use in {productname-short}.
====

---

[role="_additional-resources"]
.Additional resources
* link:https://llamastack.github.io/docs/providers/openai[OpenAI API Compatibility]
